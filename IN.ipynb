{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "548d38af-2960-46a0-8d6a-627ba42adc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from pytorch_lightning import LightningModule\n",
    "from torch_geometric.nn import aggr\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import torch.optim as optim\n",
    "from torch_scatter import scatter_add\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU, Sigmoid\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from collections import namedtuple\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29a0be8c-163d-4421-b8e7-eebfc8c8513e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted PyTorch Version: 2.2.1+cu121\n",
      "Formatted CUDA Version: 12.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TORCH = torch.__version__\n",
    "CUDA = torch.version.cuda\n",
    "\n",
    "print(f\"Formatted PyTorch Version: {TORCH}\")\n",
    "print(f\"Formatted CUDA Version: {CUDA}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9833edec-c99d-4099-a92c-1810f8e4ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, home_dir, sub_dir, preprocess=True, hparams=None):\n",
    "        self.base_path = os.path.join(home_dir, sub_dir)\n",
    "        self.file_names = self._get_file_names()\n",
    "        self.preprocess = preprocess\n",
    "        self.hparams = hparams if hparams is not None else {}\n",
    "\n",
    "    def _get_file_names(self):\n",
    "        file_names = []\n",
    "        for file_name in os.listdir(self.base_path):\n",
    "            if file_name.endswith('.pyg'):  # Adjust this condition as needed\n",
    "                file_names.append(file_name)\n",
    "        return file_names\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = os.path.join(self.base_path, file_name)\n",
    "        data = torch.load(file_path)\n",
    "        print(f\"Loaded data from {file_path}\")\n",
    "\n",
    "        # Remove 'scores' from data if it exists\n",
    "        if 'scores' in data:\n",
    "            del data['scores']\n",
    "\n",
    "        \n",
    "        if self.preprocess:\n",
    "            data = self.preprocess_event(data)\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def preprocess_event(self, data):\n",
    "        print(\"Preprocessing data\")\n",
    "        data = self.add_edge_features(data)\n",
    "        return data\n",
    "\n",
    "    def add_edge_features(self, data):\n",
    "        edge_features = self.hparams.get(\"edge_features\", [])\n",
    "        data = handle_edge_features(data, edge_features)\n",
    "        return data\n",
    "\n",
    "def handle_edge_features(data, edge_features):\n",
    "    src, dst = data.edge_index\n",
    "    \n",
    "    if \"dr\" in edge_features and not (\"dr\" in data.keys()):\n",
    "        data.dr = data.r[dst] - data.r[src]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3f06187-6077-4dbe-96d1-4ff96f274d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hparams = {\n",
    "    \"stage\": \"edge_classifier\",\n",
    "    \"model\": \"InteractionGNN2\",\n",
    "    \"input_dir\": \"/users/santoshp/standalone_IN_gnn/data/\",\n",
    "    \"stage_dir\": \"/users/santoshp/standalone_IN_gnn/\",\n",
    "    \"project\": \"Stand_alone\",\n",
    "    \"gpus\": 1,\n",
    "    \"nodes\": 1,\n",
    "    \"data_split\": [10, 5, 5],\n",
    "    \"dataset_class\": \"GraphDataset\",\n",
    "    \"undirected\": False,\n",
    "    \"weighting\": [\n",
    "        {\"weight\": 0.1, \"conditions\": {\"y\": False}},\n",
    "        {\"weight\": 0.0, \"conditions\": {\"y\": True}},\n",
    "        {\n",
    "            \"weight\": 1.0,\n",
    "            \"conditions\": {\n",
    "                \"y\": True,\n",
    "                \"pt\": [1000, float(\"inf\")],\n",
    "                \"nhits\": [3, float(\"inf\")],\n",
    "                \"primary\": True,\n",
    "                \"pdgId\": [\"not_in\", [11, -11]],\n",
    "                \"radius\": [0.0, 260.0],\n",
    "                \"eta_particle\": [-4.0, 4.0],\n",
    "                \"redundant_split_edges\": False,\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    \"edge_cut\": 0.5,\n",
    "    \"node_features\": [\n",
    "        \"r\",\n",
    "        \"phi\",\n",
    "        \"z\",\n",
    "        \"eta\",\n",
    "        \"cluster_r_1\",\n",
    "        \"cluster_phi_1\",\n",
    "        \"cluster_z_1\",\n",
    "        \"cluster_eta_1\",\n",
    "        \"cluster_r_2\",\n",
    "        \"cluster_phi_2\",\n",
    "        \"cluster_z_2\",\n",
    "        \"cluster_eta_2\",\n",
    "    ],\n",
    "    \"node_scales\": [\n",
    "        1000.0,\n",
    "        3.14159265359,\n",
    "        1000.0,\n",
    "        1.0,\n",
    "        1000.0,\n",
    "        3.14159265359,\n",
    "        1000.0,\n",
    "        1.0,\n",
    "        1000.0,\n",
    "        3.14159265359,\n",
    "        1000.0,\n",
    "        1.0,\n",
    "    ],\n",
    "    \"edge_features\": [\"dr\", \"dphi\", \"dz\", \"deta\", \"phislope\", \"rphislope\"],\n",
    "    \"hidden\": 128,\n",
    "    \"n_graph_iters\": 8,\n",
    "    \"n_node_encoder_layers\": 3,\n",
    "    \"n_edge_encoder_layers\": 3,\n",
    "    \"n_node_net_layers\": 3,\n",
    "    \"n_edge_net_layers\": 3,\n",
    "    \"n_node_decoder_layers\": 3,\n",
    "    \"n_edge_decoder_layers\": 3,\n",
    "    \"layernorm\": False,\n",
    "    \"output_layer_norm\": False,\n",
    "    \"edge_output_transform_final_layer_norm\": False,\n",
    "    \"batchnorm\": False,\n",
    "    \"output_batch_norm\": False,\n",
    "    \"edge_output_transform_final_batch_norm\": False,\n",
    "    \"bn_track_running_stats\": False,\n",
    "    \"hidden_activation\": \"ReLU\",\n",
    "    \"output_activation\": \"ReLU\",\n",
    "    \"edge_output_transform_final_activation\": None,\n",
    "    \"concat\": True,\n",
    "    \"node_net_recurrent\": False,\n",
    "    \"edge_net_recurrent\": False,\n",
    "    \"in_out_diff_agg\": True,\n",
    "    \"checkpointing\": True,\n",
    "    \"warmup\": 5,\n",
    "    \"lr\": 0.0005,\n",
    "    \"min_lr\": 0.000005,\n",
    "    \"factor\": 0.9,\n",
    "    \"patience\": 15,\n",
    "    \"max_epochs\": 1,\n",
    "    \"max_training_graph_size\": 2800000,\n",
    "    \"debug\": False,\n",
    "    \"num_workers\": [8, 8, 8],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b93e0c68-c52e-4e72-957a-52321277ea77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from /users/santoshp/standalone_IN_gnn/data/train_set/event005000002.pyg\n",
      "Preprocessing data\n",
      "DataBatch(x=[305932], edge_index=[2, 42890], y=[42890], cluster_x_2=[305932], z=[305932], r=[305932], norm_z_1=[305932], norm_y_2=[305932], cluster_z_2=[305932], cluster_y_1=[305932], hit_id=[305932], norm_y_1=[305932], phi_angle_1=[305932], cluster_r_1=[305932], cluster_phi_1=[305932], phi_angle_2=[305932], cluster_eta_2=[305932], norm_x_2=[305932], module_id=[305932], cluster_z_1=[305932], phi=[305932], norm_z_2=[305932], cluster_y_2=[305932], region=[305932], eta_angle_2=[305932], cluster_x_1=[305932], eta_angle_1=[305932], eta=[305932], norm_x_1=[305932], cluster_eta_1=[305932], cluster_phi_2=[305932], cluster_r_2=[305932], track_edges=[2, 15712], particle_id=[15712], pt=[15712], pdgId=[15712], radius=[15712], redundant_split_edges=[15712], primary=[15712], eta_particle=[15712], nhits=[15712], config=[2], event_id=[1], truth_map=[15712], phi_region_id=[1], eta_region_id=[1], weights=[42890], dr=[42890], dphi=[42890], dz=[42890], deta=[42890], phislope=[42890], rphislope=[42890], batch=[305932], ptr=[2])\n"
     ]
    }
   ],
   "source": [
    "home_dir = '/users/santoshp/standalone_IN_gnn/data/'\n",
    "\n",
    "test = 'test_set/'\n",
    "train = 'train_set/'\n",
    "val = 'val_set/'\n",
    "\n",
    "\n",
    "test_dataset = GraphDataset(home_dir, test, preprocess=True, hparams=hparams)\n",
    "train_dataset = GraphDataset(home_dir, train, preprocess=True, hparams=hparams)\n",
    "val_dataset = GraphDataset(home_dir, val, preprocess=True, hparams=hparams)\n",
    "\n",
    "\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52decc57-0236-46fe-818e-234a80d4496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 8, 'shuffle': True, 'num_workers': 0}\n",
    "train_loader = DataLoader(train_dataset,**params)  #batches join graphs instead of splitting them therefore more than train set batches will make 1 batch only \n",
    "test_loader = DataLoader(test_dataset, **params)\n",
    "val_loader = DataLoader(val_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb1eaeb4-9e52-4b56-9e53-39809deb05d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02ae7559-31f4-4e56-be3b-2a115f6c2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mlp(\n",
    "    input_size,\n",
    "    sizes,\n",
    "    hidden_activation=\"ReLU\",\n",
    "    output_activation=None,\n",
    "    layer_norm=False,  # TODO : change name to hidden_layer_norm while ensuring backward compatibility\n",
    "    output_layer_norm=False,\n",
    "    batch_norm=False,  # TODO : change name to hidden_batch_norm while ensuring backward compatibility\n",
    "    output_batch_norm=False,\n",
    "    input_dropout=0,\n",
    "    hidden_dropout=0,\n",
    "    track_running_stats=False,\n",
    "):\n",
    "    \"\"\"Construct an MLP with specified fully-connected layers.\"\"\"\n",
    "    hidden_activation = getattr(nn, hidden_activation)\n",
    "    if output_activation is not None:\n",
    "        output_activation = getattr(nn, output_activation)\n",
    "    layers = []\n",
    "    n_layers = len(sizes)\n",
    "    sizes = [input_size] + sizes\n",
    "    # Hidden layers\n",
    "    for i in range(n_layers - 1):\n",
    "        if i == 0 and input_dropout > 0:\n",
    "            layers.append(nn.Dropout(input_dropout))\n",
    "        layers.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
    "        if layer_norm:  # hidden_layer_norm\n",
    "            layers.append(nn.LayerNorm(sizes[i + 1], elementwise_affine=False))\n",
    "        if batch_norm:  # hidden_batch_norm\n",
    "            layers.append(\n",
    "                nn.BatchNorm1d(\n",
    "                    sizes[i + 1],\n",
    "                    eps=6e-05,\n",
    "                    track_running_stats=track_running_stats,\n",
    "                    affine=True,\n",
    "                )  # TODO : Set BatchNorm and LayerNorm parameters in config file ?\n",
    "            )\n",
    "        layers.append(hidden_activation())\n",
    "        if hidden_dropout > 0:\n",
    "            layers.append(nn.Dropout(hidden_dropout))\n",
    "    # Final layer\n",
    "    layers.append(nn.Linear(sizes[-2], sizes[-1]))\n",
    "    if output_activation is not None:\n",
    "        if output_layer_norm:\n",
    "            layers.append(nn.LayerNorm(sizes[-1], elementwise_affine=False))\n",
    "        if output_batch_norm:\n",
    "            layers.append(\n",
    "                nn.BatchNorm1d(\n",
    "                    sizes[-1],\n",
    "                    eps=6e-05,\n",
    "                    track_running_stats=track_running_stats,\n",
    "                    affine=True,\n",
    "                )  # TODO : Set BatchNorm and LayerNorm parameters in config file ?\n",
    "            )\n",
    "        layers.append(output_activation())\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b04e2132-fa0f-4314-b41b-defb05ad119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionGNN2(LightningModule):\n",
    "\n",
    "    \"\"\"\n",
    "    Interaction Network (L2IT version).\n",
    "    Operates on directed graphs.\n",
    "    Aggregate and reduce (sum) separately incomming and outcoming edges latents.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "\n",
    "        hparams[\"batchnorm\"] = (\n",
    "            False if \"batchnorm\" not in hparams else hparams[\"batchnorm\"]\n",
    "        )\n",
    "        hparams[\"output_batch_norm\"] = hparams.get(\"output_batch_norm\", False)\n",
    "        hparams[\"edge_output_transform_final_batch_norm\"] = hparams.get(\n",
    "            \"edge_output_transform_final_batch_norm\", False\n",
    "        )\n",
    "        hparams[\"edge_output_transform_final_batch_norm\"] = hparams.get(\n",
    "            \"edge_output_transform_final_batch_norm\", False\n",
    "        )\n",
    "        hparams[\"track_running_stats\"] = (\n",
    "            False\n",
    "            if \"track_running_stats\" not in hparams\n",
    "            else hparams[\"track_running_stats\"]\n",
    "        )\n",
    "\n",
    "        # TODO: Add equivalent check and default values for other model parameters ?\n",
    "        # TODO: Use get() method\n",
    "\n",
    "        # Define the dataset to be used, if not using the default\n",
    "        #self.save_hyperparameters(hparams)\n",
    "\n",
    "        # self.setup_layer_sizes()\n",
    "\n",
    "        if hparams[\"concat\"]:\n",
    "            if hparams[\"in_out_diff_agg\"]:\n",
    "                in_node_net = hparams[\"hidden\"] * 4\n",
    "            else:\n",
    "                in_node_net = hparams[\"hidden\"] * 3\n",
    "            in_edge_net = hparams[\"hidden\"] * 6\n",
    "        else:\n",
    "            if hparams[\"in_out_diff_agg\"]:\n",
    "                in_node_net = hparams[\"hidden\"] * 3\n",
    "            else:\n",
    "                in_node_net = hparams[\"hidden\"] * 2\n",
    "            in_edge_net = hparams[\"hidden\"] * 3\n",
    "        # node encoder\n",
    "        self.node_encoder = make_mlp(\n",
    "            input_size=len(hparams[\"node_features\"]),\n",
    "            sizes=[hparams[\"hidden\"]] * hparams[\"n_node_net_layers\"],\n",
    "            output_activation=hparams[\"output_activation\"],\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "            batch_norm=hparams[\"batchnorm\"],\n",
    "            output_batch_norm=hparams[\"output_batch_norm\"],\n",
    "            track_running_stats=hparams[\"track_running_stats\"],\n",
    "        )\n",
    "     \n",
    "        # edge encoder\n",
    "        if \"edge_features\" in hparams and len(hparams[\"edge_features\"]) != 0:\n",
    "            self.edge_encoder = make_mlp(\n",
    "                input_size=len(hparams[\"edge_features\"]),\n",
    "                sizes=[hparams[\"hidden\"]] * hparams[\"n_edge_net_layers\"],\n",
    "                output_activation=hparams[\"output_activation\"],\n",
    "                hidden_activation=hparams[\"hidden_activation\"],\n",
    "                layer_norm=hparams[\"layernorm\"],\n",
    "                batch_norm=hparams[\"batchnorm\"],\n",
    "                output_batch_norm=hparams[\"output_batch_norm\"],\n",
    "                track_running_stats=hparams[\"track_running_stats\"],\n",
    "            )\n",
    "        else:\n",
    "            self.edge_encoder = make_mlp(\n",
    "                input_size=2 * hparams[\"hidden\"],\n",
    "                sizes=[hparams[\"hidden\"]] * hparams[\"n_edge_net_layers\"],\n",
    "                output_activation=hparams[\"output_activation\"],\n",
    "                hidden_activation=hparams[\"hidden_activation\"],\n",
    "                layer_norm=hparams[\"layernorm\"],\n",
    "                batch_norm=hparams[\"batchnorm\"],\n",
    "                output_batch_norm=hparams[\"output_batch_norm\"],\n",
    "                track_running_stats=hparams[\"track_running_stats\"],\n",
    "            )\n",
    "\n",
    "        # edge network\n",
    "        if hparams[\"edge_net_recurrent\"]:\n",
    "            self.edge_network = make_mlp(\n",
    "                input_size=in_edge_net,\n",
    "                sizes=[hparams[\"hidden\"]] * hparams[\"n_edge_net_layers\"],\n",
    "                output_activation=hparams[\"output_activation\"],\n",
    "                hidden_activation=hparams[\"hidden_activation\"],\n",
    "                layer_norm=hparams[\"layernorm\"],\n",
    "                batch_norm=hparams[\"batchnorm\"],\n",
    "                output_batch_norm=hparams[\"output_batch_norm\"],\n",
    "                track_running_stats=hparams[\"track_running_stats\"],\n",
    "            )\n",
    "        else:\n",
    "            self.edge_network = nn.ModuleList(\n",
    "                [\n",
    "                    make_mlp(\n",
    "                        input_size=in_edge_net,\n",
    "                        sizes=[hparams[\"hidden\"]] * hparams[\"n_edge_net_layers\"],\n",
    "                        output_activation=hparams[\"output_activation\"],\n",
    "                        hidden_activation=hparams[\"hidden_activation\"],\n",
    "                        layer_norm=hparams[\"layernorm\"],\n",
    "                        batch_norm=hparams[\"batchnorm\"],\n",
    "                        output_batch_norm=hparams[\"output_batch_norm\"],\n",
    "                        track_running_stats=hparams[\"track_running_stats\"],\n",
    "                    )\n",
    "                    for i in range(hparams[\"n_graph_iters\"])\n",
    "                ]\n",
    "            )\n",
    "        # node network\n",
    "        if hparams[\"node_net_recurrent\"]:\n",
    "            self.node_network = make_mlp(\n",
    "                input_size=in_node_net,\n",
    "                sizes=[hparams[\"hidden\"]] * hparams[\"n_node_net_layers\"],\n",
    "                output_activation=hparams[\"output_activation\"],\n",
    "                hidden_activation=hparams[\"hidden_activation\"],\n",
    "                layer_norm=hparams[\"layernorm\"],\n",
    "                batch_norm=hparams[\"batchnorm\"],\n",
    "                output_batch_norm=hparams[\"output_batch_norm\"],\n",
    "                track_running_stats=hparams[\"track_running_stats\"],\n",
    "            )\n",
    "        else:\n",
    "            self.node_network = nn.ModuleList(\n",
    "                [\n",
    "                    make_mlp(\n",
    "                        input_size=in_node_net,\n",
    "                        sizes=[hparams[\"hidden\"]] * hparams[\"n_node_net_layers\"],\n",
    "                        output_activation=hparams[\"output_activation\"],\n",
    "                        hidden_activation=hparams[\"hidden_activation\"],\n",
    "                        layer_norm=hparams[\"layernorm\"],\n",
    "                        batch_norm=hparams[\"batchnorm\"],\n",
    "                        output_batch_norm=hparams[\"output_batch_norm\"],\n",
    "                        track_running_stats=hparams[\"track_running_stats\"],\n",
    "                    )\n",
    "                    for i in range(hparams[\"n_graph_iters\"])\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        # edge decoder\n",
    "        self.edge_decoder = make_mlp(\n",
    "            input_size=hparams[\"hidden\"],\n",
    "            sizes=[hparams[\"hidden\"]] * hparams[\"n_edge_decoder_layers\"],\n",
    "            output_activation=hparams[\"output_activation\"],\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "            batch_norm=hparams[\"batchnorm\"],\n",
    "            output_batch_norm=hparams[\"output_batch_norm\"],\n",
    "            track_running_stats=hparams[\"track_running_stats\"],\n",
    "        )\n",
    "        # edge output transform layer\n",
    "        self.edge_output_transform = make_mlp(\n",
    "            input_size=hparams[\"hidden\"],\n",
    "            sizes=[hparams[\"hidden\"], 1],\n",
    "            output_activation=hparams[\"edge_output_transform_final_activation\"],\n",
    "            hidden_activation=hparams[\"hidden_activation\"],\n",
    "            layer_norm=hparams[\"layernorm\"],\n",
    "            batch_norm=hparams[\"batchnorm\"],\n",
    "            output_batch_norm=hparams[\"edge_output_transform_final_batch_norm\"],\n",
    "            track_running_stats=hparams[\"track_running_stats\"],\n",
    "        )\n",
    "\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        # hyperparams\n",
    "        # self.hparams = hparams\n",
    "\n",
    "\n",
    "\n",
    "    ###############################\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Forward pass\n",
    "        output = self(batch)\n",
    "        \n",
    "        # Dummy loss calculation\n",
    "        loss = output.mean()\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Forward pass\n",
    "        output = self(batch)\n",
    "        \n",
    "        # Dummy loss calculation\n",
    "        loss = output.mean()\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "        \n",
    "    def testing_step(self, batch, batch_idx):\n",
    "        # Forward pass\n",
    "        output = self(batch)\n",
    "        \n",
    "        # Dummy loss calculation\n",
    "        loss = output.mean()\n",
    "\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.get(\"lr\", 0.001))\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"\n",
    "        Load the training set.\n",
    "        \"\"\"\n",
    "        return DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        \"\"\"\n",
    "        Load the val set.\n",
    "        \"\"\"\n",
    "        return DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        \"\"\"\n",
    "        Load the test set.\n",
    "        \"\"\"\n",
    "        return DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "    ###########################\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = torch.stack(\n",
    "            [batch[feature] for feature in self.hparams[\"node_features\"]], dim=-1\n",
    "        ).float()\n",
    "\n",
    "        # Same features on the 3 channels in the STRIP ENDCAP TODO: Process it in previous stage\n",
    "        mask = torch.logical_or(batch.region == 2, batch.region == 6).reshape(-1)\n",
    "        x[mask] = torch.cat([x[mask, 0:4], x[mask, 0:4], x[mask, 0:4]], dim=1)\n",
    "        # print(x[:, 8:12])\n",
    "        \n",
    "\n",
    "        if \"edge_features\" in self.hparams and len(self.hparams) != 0:\n",
    "            edge_attr = torch.stack(\n",
    "                [batch[feature] for feature in self.hparams[\"edge_features\"]], dim=-1\n",
    "            ).float()\n",
    "        else:\n",
    "            edge_attr = None\n",
    "\n",
    "        x.requires_grad = True\n",
    "        if edge_attr is not None:\n",
    "            edge_attr.requires_grad = True\n",
    "\n",
    "        # Get src and dst\n",
    "        src, dst = batch.edge_index\n",
    "\n",
    "####################\n",
    "         # Call handle_edge_features function to handle edge features\n",
    "        #handle_edge_features(batch, self.hparams.get(\"edge_features\", []))\n",
    "####################\n",
    "\n",
    "        # Encode nodes and edges features into latent spaces\n",
    "        if self.hparams[\"checkpointing\"]:\n",
    "            x = checkpoint(self.node_encoder, x)\n",
    "            if edge_attr is not None:\n",
    "                e = checkpoint(self.edge_encoder, edge_attr)\n",
    "            else:\n",
    "                e = checkpoint(self.edge_encoder, torch.cat([x[src], x[dst]], dim=-1))\n",
    "        else:\n",
    "            x = self.node_encoder(x)\n",
    "            if edge_attr is not None:\n",
    "                e = self.edge_encoder(edge_attr)\n",
    "            else:\n",
    "                e = self.edge_encoder(torch.cat([x[src], x[dst]], dim=-1))\n",
    "        # Apply dropout\n",
    "        # x = self.dropout(x)\n",
    "        # e = self.dropout(e)\n",
    "\n",
    "        # memorize initial encodings for concatenate in the gnn loop if request\n",
    "        if self.hparams[\"concat\"]:\n",
    "            input_x = x\n",
    "            input_e = e\n",
    "        # Initialize outputs\n",
    "        outputs = []\n",
    "        # Loop over gnn layers\n",
    "        for i in range(self.hparams[\"n_graph_iters\"]):\n",
    "            if self.hparams[\"checkpointing\"]:\n",
    "                if self.hparams[\"concat\"]:\n",
    "                    x = checkpoint(self.concat, x, input_x)\n",
    "                    e = checkpoint(self.concat, e, input_e)\n",
    "                if (\n",
    "                    self.hparams[\"node_net_recurrent\"]\n",
    "                    and self.hparams[\"edge_net_recurrent\"]\n",
    "                ):\n",
    "                    x, e, out = checkpoint(self.message_step, x, e, src, dst)\n",
    "                else:\n",
    "                    x, e, out = checkpoint(self.message_step, x, e, src, dst, i)\n",
    "            else:\n",
    "                if self.hparams[\"concat\"]:\n",
    "                    x = torch.cat([x, input_x], dim=-1)\n",
    "                    e = torch.cat([e, input_e], dim=-1)\n",
    "                if (\n",
    "                    self.hparams[\"node_net_recurrent\"]\n",
    "                    and self.hparams[\"edge_net_recurrent\"]\n",
    "                ):\n",
    "                    x, e, out = self.message_step(x, e, src, dst)\n",
    "                else:\n",
    "                    x, e, out = self.message_step(x, e, src, dst, i)\n",
    "            outputs.append(out)\n",
    "        return outputs[-1].squeeze(-1)\n",
    "\n",
    "    def message_step(self, x, e, src, dst, i=None):\n",
    "        #print(\"Shape of e tensor:\", e.size())\n",
    "        #print(\"Shape of x[src] tensor:\", x[src].size())\n",
    "        #print(\"Shape of x[dst] tensor:\", x[dst].size())\n",
    "        \n",
    "        #assert e.shape[0] == x[src].shape[0] #\"Number of rows in e and x[src] must match\"\n",
    "        x_src = x[src].unsqueeze(0)  # Add an extra dimension\n",
    "        x_dst = x[dst].unsqueeze(0)  # Add an extra dimension\n",
    "\n",
    "\n",
    "        edge_inputs = torch.cat([e, x[src], x[dst]], dim=-1)  # order dst src x ?\n",
    "        if self.hparams[\"edge_net_recurrent\"]:\n",
    "            e_updated = self.edge_network(edge_inputs)\n",
    "        else:\n",
    "            e_updated = self.edge_network[i](edge_inputs)\n",
    "        # Update nodes\n",
    "        edge_messages_from_src = scatter_add(e_updated, dst, dim=0, dim_size=x.shape[0])\n",
    "        edge_messages_from_dst = scatter_add(e_updated, src, dim=0, dim_size=x.shape[0])\n",
    "        if self.hparams[\"in_out_diff_agg\"]:\n",
    "            node_inputs = torch.cat(\n",
    "                [edge_messages_from_src, edge_messages_from_dst, x], dim=-1\n",
    "            )  # to check : the order dst src  x ?\n",
    "        else:\n",
    "            # add message from src and dst ?? # edge_messages = edge_messages_from_src + edge_messages_from_dst\n",
    "            edge_messages = edge_messages_from_src + edge_messages_from_dst\n",
    "            node_inputs = torch.cat([edge_messages, x], dim=-1)\n",
    "        # x_updated = self.dropout(self.node_network[i](node_inputs))\n",
    "        if self.hparams[\"node_net_recurrent\"]:\n",
    "            x_updated = self.node_network(node_inputs)\n",
    "        else:\n",
    "            x_updated = self.node_network[i](node_inputs)\n",
    "\n",
    "        return (\n",
    "            x_updated,\n",
    "            e_updated,\n",
    "            self.edge_output_transform(self.edge_decoder(e_updated)),\n",
    "        )\n",
    "\n",
    "    def concat(self, x, y):\n",
    "        return torch.cat([x, y], dim=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82c2841f-516f-4006-b44e-51fb793bf4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InteractionGNN2(\n",
       "  (node_encoder): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (edge_encoder): Sequential(\n",
       "    (0): Linear(in_features=6, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (edge_network): ModuleList(\n",
       "    (0-7): 8 x Sequential(\n",
       "      (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (node_network): ModuleList(\n",
       "    (0-7): 8 x Sequential(\n",
       "      (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (edge_decoder): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (edge_output_transform): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = InteractionGNN2(hparams)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "504aabfb-86be-4b24-81aa-07db129e35eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                  | Type       | Params\n",
      "-----------------------------------------------------\n",
      "0 | node_encoder          | Sequential | 34.7 K\n",
      "1 | edge_encoder          | Sequential | 33.9 K\n",
      "2 | edge_network          | ModuleList | 1.1 M \n",
      "3 | node_network          | ModuleList | 789 K \n",
      "4 | edge_decoder          | Sequential | 49.5 K\n",
      "5 | edge_output_transform | Sequential | 16.6 K\n",
      "6 | dropout               | Dropout    | 0     \n",
      "-----------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "7.904     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]Loaded data from /users/santoshp/standalone_IN_gnn/data/val_set/event005000003.pyg\n",
      "Preprocessing data\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             Loaded data from /users/santoshp/standalone_IN_gnn/data/train_set/event005000002.pyg\n",
      "Preprocessing data\n",
      "Epoch 0: 100%|██████████| 1/1 [00:51<00:00,  0.02it/s, v_num=60, train_loss_step=0.055]Loaded data from /users/santoshp/standalone_IN_gnn/data/val_set/event005000003.pyg\n",
      "Preprocessing data\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:10<00:00,  0.09it/s]\u001b[A\n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=60, train_loss_step=0.055, val_loss=0.0182, train_loss_epoch=0.055]        Loaded data from /users/santoshp/standalone_IN_gnn/data/train_set/event005000002.pyg\n",
      "Preprocessing data\n",
      "Epoch 1: 100%|██████████| 1/1 [00:52<00:00,  0.02it/s, v_num=60, train_loss_step=0.0192, val_loss=0.0182, train_loss_epoch=0.055]Loaded data from /users/santoshp/standalone_IN_gnn/data/val_set/event005000003.pyg\n",
      "Preprocessing data\n",
      "\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:11<00:00,  0.09it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 1/1 [01:06<00:00,  0.02it/s, v_num=60, train_loss_step=0.0192, val_loss=-0.0312, train_loss_epoch=0.0192]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [01:06<00:00,  0.02it/s, v_num=60, train_loss_step=0.0192, val_loss=-0.0312, train_loss_epoch=0.0192]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=2)\n",
    "trainer.fit(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bff40ae-5d47-4e89-95be-f93b29703321",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'complete_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abd72a36-c40d-48a9-bdfc-b37c1d2475f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InteractionGNN2(\n",
       "  (node_encoder): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (edge_encoder): Sequential(\n",
       "    (0): Linear(in_features=6, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (edge_network): ModuleList(\n",
       "    (0-7): 8 x Sequential(\n",
       "      (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (node_network): ModuleList(\n",
       "    (0-7): 8 x Sequential(\n",
       "      (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (edge_decoder): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (edge_output_transform): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('complete_model.pth')\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0662aa51-0eb4-49ea-ba93-b4b5eee9599b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from /users/santoshp/standalone_IN_gnn/data/val_set/event005000003.pyg\n",
      "Preprocessing data\n",
      "tensor([ 0.0078, -0.0145, -0.0326,  ..., -0.2122, -0.2273, -0.2223])\n",
      "39573\n",
      "tensor([0.0078, 0.0099, 0.0036,  ..., 0.0007, 0.0019, 0.0033])\n",
      "16543\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        edge_scores = model(batch)\n",
    "        print(edge_scores)\n",
    "        print(edge_scores.size(0))\n",
    "        positive_scores = edge_scores[edge_scores > 0]\n",
    "        print(positive_scores)\n",
    "        print(positive_scores.size(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
